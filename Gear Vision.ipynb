{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project...\n",
      "uploading images\n",
      "Training...\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Training\n",
      "Training status: Completed\n",
      "Done!\n",
      "\thardshell jacket: 75.18%\n",
      "\tinsulated jacket: 0.61%\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageUrlCreateEntry\n",
    "\n",
    "ENDPOINT = \"https://southcentralus.api.cognitive.microsoft.com\"\n",
    "\n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = \"791e1322535143ee9cd521619b177aec\"\n",
    "prediction_key = \"caf62a2517034d91940356abf13fda1e\"\n",
    "trainer = CustomVisionTrainingClient(training_key, endpoint=ENDPOINT)\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"JacketClassifier\")\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "hardshell_jacket_tag = trainer.create_tag(project.id, \"hardshell jacket\")\n",
    "insulated_jacket_tag = trainer.create_tag(project.id, \"insulated jacket\")\n",
    "\n",
    "\n",
    "print(\"uploading images\")\n",
    "# In[43]:\n",
    "#trainer.create_images_from_files()\n",
    "#trainer.create_images_from_files()\n",
    "import os \n",
    "root = r'C://Users/changgoo.kang/'\n",
    "\n",
    "hardshell_dir = r'resize_images/hardshell_jackets'\n",
    "insulated_dir = r'resize_images/insulated_jackets'\n",
    "for img1 in os.listdir(os.path.join(root,hardshell_dir)):\n",
    "    img1 = os.path.join(root,hardshell_dir,img1)\n",
    "    with open(img1,'rb') as f:\n",
    "        trainer.create_images_from_data(project.id, f.read(),[hardshell_jacket_tag.id])\n",
    "\n",
    "\n",
    "# In[44]:\n",
    "#trainer.create_images_from_files()\n",
    "for img1 in os.listdir(os.path.join(root,insulated_dir)):\n",
    "    img1 = os.path.join(root,insulated_dir,img1)\n",
    "    with open(img1,'rb') as f:\n",
    "        trainer.create_images_from_data(project.id, f.read(),[insulated_jacket_tag.id])\n",
    "        \n",
    "import time\n",
    "\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Make it the default project endpoint\n",
    "trainer.update_iteration(project.id, iteration.id, is_default=True)\n",
    "print (\"Done!\")\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)\n",
    "\n",
    "test_img_url = 'https://www.sport-bittl.com/images/product_images/popup_images/56551804A_apex_flex_gtx_jacke_herren_red.jpg'\n",
    "results = predictor.predict_image_url(project.id, iteration.id, url=test_img_url)\n",
    "\n",
    "# Display the results.\n",
    "for prediction in results.predictions:\n",
    "    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinsulated jacket: 100.00%\n",
      "\thardshell jacket: 0.00%\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x000001FC9DD86048>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-557e88f7aaf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mimg2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#a=fig.add_subplot(1,2,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2517\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[1;32m-> 2519\u001b[1;33m                   % (filename if filename else fp))\n\u001b[0m\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x000001FC9DD86048>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Needed to display matplotlib plots in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)\n",
    "\n",
    "#test_img1 = \"https://www.sport-bittl.com/images/product_images/popup_images/56551804A_apex_flex_gtx_jacke_herren_red.jpg\"\n",
    "test_img2 = \"http://www.bikepacking.com/wp-content/uploads/2015/10/down-jacket-05-740x494.jpg\"\n",
    "\n",
    "#results1 = predictor.predict_image_url(project.id, iteration.id, url=test_img1)\n",
    "results2 = predictor.predict_image_url(project.id, iteration.id, url=test_img2)\n",
    "\n",
    "# Display the results.\n",
    "#for prediction in results1.predictions:\n",
    "#    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))\n",
    "    \n",
    "for prediction in results2.predictions:\n",
    "    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))   \n",
    "    \n",
    "    \n",
    "# Create a figure to display the images\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "# Open it and add it to the figure (in a 4-row grid)\n",
    "\n",
    "#response = requests.get(test_img1, stream=True)\n",
    "#response.raw.decode_content=True\n",
    "#img1=Image.open(response.raw)\n",
    "\n",
    "\n",
    "#response = requests.get(test_img2, stream=True)\n",
    "#response.raw.decode_content=True\n",
    "#img2=Image.open(response.raw)\n",
    "\n",
    "#a=fig.add_subplot(1,2,1)\n",
    "#imgplot = plt.imshow(img1)\n",
    "#a.set_title(results1.predictions[0].tag_name)\n",
    "\n",
    "b=fig.add_subplot(1,2,2)\n",
    "imgplot = plt.imshow(img2)\n",
    "b.set_title(results2.predictions[0].tag_name)\n",
    "\n",
    "# Add the folder name (the class of the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinsulated jacket: 100.00%\n",
      "\thardshell jacket: 0.00%\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x000001FC9C8DF570>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-99ba37e46bc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#response = requests.get(test_img2,stream=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2517\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2518\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[1;32m-> 2519\u001b[1;33m                   % (filename if filename else fp))\n\u001b[0m\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x000001FC9C8DF570>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Needed to display matplotlib plots in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)\n",
    "\n",
    "#test_img1 = \"https://www.sport-bittl.com/images/product_images/popup_images/56551804A_apex_flex_gtx_jacke_herren_red.jpg\"\n",
    "test_img2 = \"http://www.bikepacking.com/wp-content/uploads/2015/10/down-jacket-05-740x494.jpg\"\n",
    "\n",
    "#results1 = predictor.predict_image_url(project.id, iteration.id, url=test_img1)\n",
    "results2 = predictor.predict_image_url(project.id, iteration.id, url=test_img2)\n",
    "\n",
    "# Display the results.\n",
    "#for prediction in results1.predictions:\n",
    "#    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))\n",
    "    \n",
    "for prediction in results2.predictions:\n",
    "    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))   \n",
    "    \n",
    "    \n",
    "# Create a figure to display the images\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "# Open it and add it to the figure (in a 4-row grid)\n",
    "#response = requests.get(test_img1, stream=True)\n",
    "#response.raw.decode_content=True\n",
    "#img1=Image.open(response.raw)\n",
    "\n",
    "#response = requests.get(test_img2, stream=True)\n",
    "#response.raw.decode_content=True\n",
    "#img2=Image.open(response.raw)\n",
    "\n",
    "img_name = os.path.basename(test_img2)\n",
    "open(img_name, 'wb')\n",
    "\n",
    "#response = requests.get(test_img2,stream=True)\n",
    "#img2 = Image.open(BytesIO(response.content))\n",
    "\n",
    "#a=fig.add_subplot(1,2,1)\n",
    "#imgplot = plt.imshow(img1)\n",
    "#a.set_title(results1.predictions[0].tag_name)\n",
    "\n",
    "b=fig.add_subplot(1,2,2)\n",
    "imgplot = plt.imshow(img2)\n",
    "b.set_title(results2.predictions[0].tag_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "HttpOperationError",
     "evalue": "Operation returned an invalid status code 'Bad Request'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpOperationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2650f358dc72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#results2 = predictor.predict_image(project.id, test_img2, iteration.id )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mresults2\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_img2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapplication\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_headers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Create a figure to display the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azure\\cognitiveservices\\vision\\customvision\\prediction\\custom_vision_prediction_client.py\u001b[0m in \u001b[0;36mpredict_image\u001b[1;34m(self, project_id, image_data, iteration_id, application, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHttpOperationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mdeserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHttpOperationError\u001b[0m: Operation returned an invalid status code 'Bad Request'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Needed to display matplotlib plots in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=ENDPOINT)\n",
    "\n",
    "test_img1 = \"C://Users/changgoo.kang/gear_images/test/test1.jpeg\"\n",
    "test_img2 = \"C://Users/changgoo.kang/gear_images/test/test2.jpeg\"\n",
    "\n",
    "#results2 = predictor.predict_image(project.id, test_img2, iteration.id )\n",
    "results2 =  predictor.predict_image(project.id, test_img2, iteration.id, application=None, custom_headers=None, raw=False)\n",
    "    \n",
    "# Create a figure to display the images\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "# Open it and add it to the figure (in a 4-row grid)\n",
    "\n",
    "img1 = Image.open(test_img1)\n",
    "\n",
    "img2 = Image.open(test_img2)\n",
    "\n",
    "a=fig.add_subplot(1,2,1)\n",
    "imgplot = plt.imshow(img1)\n",
    "a.set_title(results1.predictions[0].tag_name)\n",
    "\n",
    "b=fig.add_subplot(1,2,2)\n",
    "imgplot = plt.imshow(img2)\n",
    "b.set_title(results2.predictions[0].tag_name)\n",
    "\n",
    "# Add the folder name (the class of the image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
